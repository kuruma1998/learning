{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session9 - playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat here the creation of the neural network from session9.\n",
    "\n",
    "以下はsession9でのニューラルネットワークの作成のコードのコピーです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:09:18.660060: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-26 11:09:18.660986: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "vector_input = Input(shape = (784,), name='input')\n",
    "fc1 = Dense(128, activation='relu', name='fc1')(vector_input)\n",
    "fc2 = Dense(128, activation='relu', name='fc2')(fc1)\n",
    "output = Dense(10, activation='softmax', name='output')(fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_network = Model(vector_input, output, name='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "example_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK1\n",
    "- Create a network with a structure like the one above, but with one more hidden layer with 64 neurons just before the output layer.\n",
    "- Change the activation of the layers from `relu` to `tanh` (hyperbolic tangent - it is sometimes used as activation, although relu is usually better).\n",
    "- Use the `summary` function to check the number of trainable parameters.\n",
    "\n",
    "- 上記のような構のニューラルネットワークを作成してください。ただし、出力層の前に、さらに64個のニューロンの隠れ層を追加してください。 \n",
    "- すべての層の活性化関数を`relu`から`tanh`に変更してください。（`tanh`は双曲線正接です。活性化関数として使用されることもありますが、通常は`relu`の方がよりいいです。）\n",
    "- `summary`関数を使って新しいネットワークの訓練可能なパラメータの数を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 35000\n",
      "Testing set size: 35000\n",
      "Input shape: (784,)\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "#-----preparing the tools\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#-----loding the data\n",
    "from mnist_loader import MNISTVectorLoader\n",
    "# 43 is used to initialize the random generator in the object\n",
    "mnist_vector_loader = MNISTVectorLoader(43)\n",
    "X, y = mnist_vector_loader.samples(70000)\n",
    "\n",
    "#-----splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Testing set size:\", X_test.shape[0])\n",
    "\n",
    "#-----applying standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#-----Creating a fully connected network \n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "print(\"Input shape:\", input_shape)\n",
    "\n",
    "vector_input = Input(shape = (784,), name='input')\n",
    "fc1 = Dense(128, activation='tanh', name='fc1')(vector_input)\n",
    "fc2 = Dense(128, activation='tanh', name='fc2')(fc1)\n",
    "fc3 = Dense(64, activation='tanh', name='fc3')(fc2)\n",
    "output = Dense(10, activation='softmax', name='output')(fc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 125,898\n",
      "Trainable params: 125,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "example_network = Model(vector_input, output, name='classification')\n",
    "example_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL 1\n",
    "\n",
    "Create a so-called \"Autoencoder\" neural network. This is a network which has the same number of inputs and outputs, whereas in the middle hidden layer it has less neurons that the number of inputs. For the activation function in the hidden layers use `relu` and for the output layer `linear`. Set the number of neurons per layer as follows: \n",
    "\n",
    "いわゆる「オートエンコーダ」ニューラルネットワークを作成しましょう。入力と出力の数が同じ、中間の隠れ層のニューロンの数が入力より少ない、という構造を持つネットワークです。隠れ層の活性化関数には`relu`、出力層には` linear`を使ってください。層ごとのニューロン数は次のように設定してください。\n",
    "\n",
    "> input -> 128 -> 64 -> 32 -> 64 -> 128 -> output\n",
    "\n",
    "Use `summary` to print out the network structure.\n",
    "\n",
    "ネットワーク構造を`summary`を使ってプリントしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (784,)\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "input_shape = X_train[0].shape\n",
    "print(\"Input shape:\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_input = Input(shape = (784,), name='input')\n",
    "fc1 = Dense(128, activation='relu', name='fc1')(vector_input)\n",
    "fc2 = Dense(64, activation='relu', name='fc2')(fc1)\n",
    "fc3 = Dense(32, activation='relu', name='fc3')(fc2)\n",
    "fc4 = Dense(64, activation='relu', name='fc4')(fc3)\n",
    "fc5 = Dense(128, activation='relu', name='fc5')(fc4)\n",
    "output = Dense(10, activation='linear', name='output')(fc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 122,538\n",
      "Trainable params: 122,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "example_network = Model(vector_input, output, name='classification')\n",
    "example_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
